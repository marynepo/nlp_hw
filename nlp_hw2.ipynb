{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymystem3 import Mystem\n",
    "import natasha\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "import spacy\n",
    "from flair.models import SequenceTagger\n",
    "from flair.tokenization import SegtokSentenceSplitter\n",
    "from nltk import word_tokenize\n",
    "import en_core_web_sm\n",
    "from razdel import sentenize, tokenize\n",
    "from navec import Navec\n",
    "from slovnet import Morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Segmenter' from 'natasha' (/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/natasha/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-4dd6b2bef100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from natasha import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mSegmenter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mMorphVocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mNewsEmbedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Segmenter' from 'natasha' (/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/natasha/__init__.py)"
     ]
    }
   ],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тексты сложные для разметки, поскольку:\n",
    "    1) Русский: конверсия (лучше), аббр. (ВШЭ), похожие формы у разных частей речи (кр. прич. vs кр. прил.), заимств. (лонгслив), разговорные (когдатошний)\n",
    "    2) Англ: конверсия (water, repeat), сленг(do, obvs), аббревиатура (OP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_txt = 'ВШЭ_N была_V создана_V в_PP конце_N прошлого_ADJ века_N. Он_PN был_V красив_ADJ. Я_PN сделаю_V это_PN лучше_ADV тебя_PN. Этот_PN вариант_N лучше_ADJ предыдущего_ADJ. Я_PN пойду_V в_PP ванную_N. Ты_PN пойдешь_V в_PP ванную_ADJ комнату_N? Я_PN встретил_V свою_PN когдатошнюю_ADJ знакомую_N Бетти_N. У_PP него_PN был_V знакомый_ADJ голос_N. Петровы_N и_C Муравьев_N, подойдите_V сюда_ADV. Теперь_ADV можно_V и_C почилить_V. Вань_N, быстро_ADV положи_V лонгслив_N на_PP стол_N. Я_PN вывел_V своих_PN гончих_N на_PP прогулку_N. На_PP каникулах_N доделайте_V пятый_NUM номер_N. Хорошо_I, я_PN это_PN сделаю_V. Таков_PN твой_PN ответ_N? Эх_I, это_P совсем_ADV не_P жиза_N. Гугл_N подсказал_V, что_C дисплей_N телефона_N состоит_V из_PP жидкокристаллических_ADJ ячеек_N, рассеивателей_N подсветки_N, шлейфа_N с_PP коннектором_N и_C закаленного_ADJ стекла_N. Предложение_N, добивающее_V этот_PN странный_ADJ текст_N до_PP ста_NUM слов_N.'\n",
    "eng_txt = \"I_PN drink_V water_N and_C water_N the_ART plants_N every_PN day_N. I_PN should_V jolly_ADV well_ADV think_V so_ADV! There_T was_V a_ART large_ADJ increase_N in_PP our_PN sales_N numbers_N. How_ADV can_V I_PN increase_V my_PN income_N? Robert_N aced_V his_PN physics_N exam_N! Should_V we_PN refund_V their_PN money_N? She_PN asked_V for_PP a_ART refund_N because_C the_ART product_N was_V defective_ADJ. Are_V you_PN going_V to_PP her_PN birthday_N do_N next_ADJ week_N? Well_I, he_PN must_V be_V nevertiree_N. This_PN situation_N is_V a_ART repeat_N of_PP what_PN happened_V last_ADJ year_N. Could_V you_PN repeat_V that_PN please_I? I_PN mean_V, obvs_ADV everyone_PN has_V played_V their_PN part_N, even_P Anya_N, but_C London_N is_V so_P back_ADJ? OP_N said_V nothing_PN about_PP it_PN.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tag = {'N': ['S', 'NOUN', 'NN', 'NNS', 'NNP', 'NNPS', 'PROPN'], 'V': ['V', 'PRP$', 'VB', 'VBZ', 'VBG', 'VERB', 'INFN', 'PRTF', 'VBN', 'PRTS', 'GRND', 'AUX', 'VBP', 'MD', 'VBD'], 'PP': ['PR', 'PREP', 'PART', 'ADP', 'IN', 'TO'], 'ADJ': ['A', 'ADJF', 'ADJS', 'JJ'], 'ADV': ['ADV', 'ADVPRO', 'ADVB', 'PRED', 'ADP', 'RB', 'WRB'], 'PN': ['APRO', 'SPRO', 'NPRO', 'PRON', 'DET', 'PRP', 'WP', 'PRP$', 'DT'], 'NUM': ['NUM', 'ANUM', 'NUMR'], 'C': ['CONJ', 'CC', 'CCONJ', 'SCONJ'], 'I': ['INTJ', 'UH'], 'P': ['PRCL', 'PART', 'RB'], 'ART': ['DET', 'ART', 'DT'], 'T': ['DET', 'EX']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_tags(text):\n",
    "    \n",
    "    tags = re.findall('_([A-Z]+)', text)\n",
    "    clean_txt = re.sub('_[A-Z]+', '', text)\n",
    "    \n",
    "    return tags, clean_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_tg, ru_t = get_text_tags(ru_txt)\n",
    "ru_cltxt = re.sub('[.,:?!]', '', ru_t)\n",
    "pr_tags = ['']*len(ru_tg)\n",
    "ru_words = ru_cltxt.split()\n",
    "\n",
    "en_tg, en_t = get_text_tags(eng_txt)\n",
    "en_cltxt = re.sub('[.,:?!]', '', en_t)\n",
    "en_words = en_cltxt.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pymorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy пайморфи: 0.8039\n"
     ]
    }
   ],
   "source": [
    "m = MorphAnalyzer()\n",
    "for i in range(len(ru_tg)):\n",
    "    t = str(m.parse(ru_words[i])[0].tag.POS)\n",
    "    if t in dic_tag[ru_tg[i]]:\n",
    "        pr_tags[i] = ru_tg[i]\n",
    "    else:\n",
    "        pr_tags[i] = t\n",
    "print(\"Accuracy пайморфи: %.4f\" % accuracy_score(pr_tags, ru_tg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy майстема: 0.9412\n"
     ]
    }
   ],
   "source": [
    "ms = Mystem()\n",
    "ana = ms.analyze(ru_t)\n",
    "pr_tags = ['']*len(ru_tg)\n",
    "ts = []\n",
    "for word in ana:\n",
    "    if 'analysis' in word:\n",
    "        if len(word['analysis']) > 0:\n",
    "            gr = word['analysis'][0]['gr']\n",
    "            t = gr.split('=')[0].split(',')[0]\n",
    "        else:\n",
    "            t = 'none'\n",
    "        ts.append(t)\n",
    "            \n",
    "for i in range(len(ru_tg)):\n",
    "    if ts[i] in dic_tag[ru_tg[i]]:\n",
    "        pr_tags[i] = ru_tg[i]\n",
    "    else:\n",
    "        pr_tags[i] = ts[i]\n",
    "        \n",
    "print(\"Accuracy майстема: %.4f\" % accuracy_score(pr_tags, ru_tg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'navec_news_v1_1B_250K_300d_100q.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-244-1c1255f02553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnavec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNavec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'navec_news_v1_1B_250K_300d_100q.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmorph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'slovnet_morph_news_v1.tar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnavec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnavec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmarkup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mru_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/navec/navec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mTar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/navec/tar.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1571\u001b[0m                     \u001b[0msaved_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mReadError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1638\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1639\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'navec_news_v1_1B_250K_300d_100q.tar'"
     ]
    }
   ],
   "source": [
    "navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')\n",
    "morph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)\n",
    "morph.navec(navec)\n",
    "markup = next(morph.map(ru_words))\n",
    "\n",
    "for i in range(len(markup.tokens)):\n",
    "    if markup.tokens[i].pos in dic_tag[en_tg[i]]: #у меня небольшие трабблы с наташей, поэтому не могу проверить, так ли достается pos\n",
    "        pr_tags[i] = en_tg[i]\n",
    "    else:\n",
    "        pr_tags[i] = markup.tokens[i].pos\n",
    "            \n",
    "print(\"Accuracy SpaCy: %.4f\" % accuracy_score(pr_tags, en_tg))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SpaCy: 0.9192\n"
     ]
    }
   ],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(en_cltxt)\n",
    "pr_tags = [''] * len(doc)\n",
    "\n",
    "for i in range(len(doc)):\n",
    "    if doc[i].pos_ in dic_tag[en_tg[i]]:\n",
    "        pr_tags[i] = en_tg[i]\n",
    "    else:\n",
    "        pr_tags[i] = doc[i].pos_\n",
    "            \n",
    "print(\"Accuracy SpaCy: %.4f\" % accuracy_score(pr_tags, en_tg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-18 22:35:59,889 loading file /home/marynepo/.flair/models/en-pos-ontonotes-v0.5.pt\n"
     ]
    }
   ],
   "source": [
    "splitter = SegtokSentenceSplitter()\n",
    "sentences = splitter.split(en_t)\n",
    "tagger = SequenceTagger.load('pos')\n",
    "tagger.predict(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Flair: 0.9192\n"
     ]
    }
   ],
   "source": [
    "pr_tags = []\n",
    "for s in sentences:\n",
    "    s = s.to_tagged_string()\n",
    "    s = re.sub('<[.,]>', '', s)\n",
    "    tgs = re.findall('<(.+?)>', s)\n",
    "    pr_tags += tgs\n",
    "    \n",
    "for i in range(len(en_tg)):\n",
    "    if pr_tags[i] in dic_tag[en_tg[i]]:\n",
    "        pr_tags[i] = en_tg[i]\n",
    "    \n",
    "print(\"Accuracy Flair: %.4f\" % accuracy_score(pr_tags, en_tg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy NLTK: 0.8687\n"
     ]
    }
   ],
   "source": [
    "pr_tags = [''] * len(en_tg)\n",
    "ttext = nltk.pos_tag(word_tokenize(en_cltxt))\n",
    "for i in range(len(ttext)):\n",
    "    if ttext[i][1] in dic_tag[en_tg[i]]:\n",
    "        pr_tags[i] = en_tg[i]\n",
    "    else:\n",
    "        pr_tags[i] = ttext[i][1] \n",
    "        \n",
    "print(\"Accuracy NLTK: %.4f\" % accuracy_score(pr_tags, en_tg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не успела написать функцию, но взяла бы, во-первых прил. + сущ. (мне кажется, что (если говорить про отзывы) именно прил. часто имеют яркок-выраженый позитив. или негативную окраску). И также посмотрела бы на частицы (so, так) + нар./прил, кажется, часто такие сочетания будут не нейтральными, а частицы будут усилительными."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
