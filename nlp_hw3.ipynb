{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашняя работа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/nltk/lm/counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, defaultdict\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "import logging\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  target  \\\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4   \n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1   \n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14   \n",
       "\n",
       "            target_names  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.content.values.tolist()\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "texts = data_lemmatized\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прогоняем через генсим с маллетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(19,\n",
      "  [('window', 0.03419808653563432),\n",
      "   ('run', 0.019112025874742724),\n",
      "   ('set', 0.019066790310542148),\n",
      "   ('application', 0.018116843462330084),\n",
      "   ('problem', 0.018026372333928935),\n",
      "   ('server', 0.0156062696491982),\n",
      "   ('call', 0.013683758170673783),\n",
      "   ('work', 0.013525433695971773),\n",
      "   ('find', 0.011037477664940176),\n",
      "   ('display', 0.009793499649424378)]),\n",
      " (11,\n",
      "  [('line', 0.05276666206706223),\n",
      "   ('buy', 0.03151648958189596),\n",
      "   ('price', 0.026355733406927005),\n",
      "   ('good', 0.02599696426107355),\n",
      "   ('sell', 0.02467227818407617),\n",
      "   ('mail', 0.02022906030081413),\n",
      "   ('sale', 0.019263143369670208),\n",
      "   ('interested', 0.016889747481716573),\n",
      "   ('call', 0.013274458396577895),\n",
      "   ('cost', 0.012832896370912101)]),\n",
      " (7,\n",
      "  [('game', 0.03315688562854285),\n",
      "   ('year', 0.028926308769589862),\n",
      "   ('team', 0.028363621207069024),\n",
      "   ('play', 0.025237579193064356),\n",
      "   ('player', 0.019610703567855953),\n",
      "   ('win', 0.0175891963987996),\n",
      "   ('good', 0.016818106035345115),\n",
      "   ('season', 0.01206652217405802),\n",
      "   ('hit', 0.009669889963321108),\n",
      "   ('lose', 0.009503167722574191)]),\n",
      " (12,\n",
      "  [('people', 0.0460568090420353),\n",
      "   ('thing', 0.04065952673242179),\n",
      "   ('make', 0.039008593320069423),\n",
      "   ('good', 0.024107860982940356),\n",
      "   ('bad', 0.017673453837361894),\n",
      "   ('feel', 0.013651949371375354),\n",
      "   ('happen', 0.0128899801041358),\n",
      "   ('point', 0.011874021081149728),\n",
      "   ('wrong', 0.010561740676459383),\n",
      "   ('write', 0.010286585107733988)]),\n",
      " (9,\n",
      "  [('file', 0.02780436863632408),\n",
      "   ('image', 0.022756940214080586),\n",
      "   ('software', 0.022561134801148724),\n",
      "   ('version', 0.017992341832738665),\n",
      "   ('program', 0.01786180489078409),\n",
      "   ('color', 0.01618658080236707),\n",
      "   ('include', 0.014228526673048473),\n",
      "   ('graphic', 0.012836132625533027),\n",
      "   ('package', 0.01237925332869202),\n",
      "   ('format', 0.010334174571403707)]),\n",
      " (6,\n",
      "  [('car', 0.04078586807594441),\n",
      "   ('bike', 0.01551184184771971),\n",
      "   ('ride', 0.010789782736347621),\n",
      "   ('engine', 0.00946858485026424),\n",
      "   ('drive', 0.009370718340183989),\n",
      "   ('good', 0.008489919749461734),\n",
      "   ('turn', 0.008416519866901546),\n",
      "   ('time', 0.008392053239381483),\n",
      "   ('speed', 0.007853787433940105),\n",
      "   ('back', 0.007535721276179292)]),\n",
      " (0,\n",
      "  [('file', 0.027896574724369287),\n",
      "   ('post', 0.02511084082081061),\n",
      "   ('send', 0.02199160356260054),\n",
      "   ('information', 0.018401538039000274),\n",
      "   ('address', 0.0176364421077412),\n",
      "   ('list', 0.016439753599874447),\n",
      "   ('mail', 0.015144975870051399),\n",
      "   ('internet', 0.01330089849727312),\n",
      "   ('email', 0.012987012987012988),\n",
      "   ('number', 0.012712363165535371)]),\n",
      " (1,\n",
      "  [('key', 0.039591118927236754),\n",
      "   ('system', 0.016597054297647833),\n",
      "   ('encryption', 0.014640580347329084),\n",
      "   ('bit', 0.012772037810507803),\n",
      "   ('chip', 0.012310397889646076),\n",
      "   ('government', 0.012112552209276765),\n",
      "   ('public', 0.011694877995163772),\n",
      "   ('technology', 0.01149703231479446),\n",
      "   ('message', 0.010244009672455485),\n",
      "   ('security', 0.01017806111233238)]),\n",
      " (10,\n",
      "  [('ax', 0.19363046868587375),\n",
      "   ('line', 0.168677665599606),\n",
      "   ('max', 0.156037100878273),\n",
      "   ('host', 0.10436674054009686),\n",
      "   ('nntp_poste', 0.044241976524665515),\n",
      "   ('organization', 0.03365345153082164),\n",
      "   ('reply', 0.026060904539111876),\n",
      "   ('ca', 0.015964869079865385),\n",
      "   ('nntp_posting', 0.01026019863744562),\n",
      "   ('keyword', 0.007182139046211935)]),\n",
      " (3,\n",
      "  [('make', 0.022060591488338544),\n",
      "   ('work', 0.0175522962250541),\n",
      "   ('money', 0.013745291336058348),\n",
      "   ('people', 0.012643263605033261),\n",
      "   ('year', 0.012122305041275948),\n",
      "   ('job', 0.01194197323074457),\n",
      "   ('government', 0.010318986935962171),\n",
      "   ('pay', 0.009818065240041677),\n",
      "   ('group', 0.009798028372204858),\n",
      "   ('time', 0.008235152680932917)])]\n",
      "\n",
      "Coherence Score:  0.5427497122150474\n"
     ]
    }
   ],
   "source": [
    "mallet_path = '/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/mallet-2.0.8/bin/mallet'\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)\n",
    "\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, находящая оптимальное кол-во топиков. Можно интервал, на котором выбирается лучшее число топиков ([a, b] с шагом k). Я взяла небольшой интервал, потому что работает очень долго, но в принципе, можно изменить шаг и расширить интервал и посмотреть точнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_top_num(mallet_path, a, b, k):\n",
    "    b_num = 1\n",
    "    b_ch = 0\n",
    "    for i in tqdm(range(a, b+1, k)):\n",
    "        ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=i, id2word=id2word)\n",
    "        coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "        coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "        if b_ch < coherence_ldamallet:\n",
    "            b_num = i\n",
    "            b_ch = coherence_ldamallet\n",
    "            b_model = ldamallet\n",
    "    return b_num, b_ch, b_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 1/6 [01:11<05:57, 71.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 2/6 [02:28<04:52, 73.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 3/6 [03:48<03:45, 75.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 4/6 [05:18<02:39, 79.73s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 5/6 [07:11<01:29, 89.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 6/6 [09:12<00:00, 92.07s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.5437548459723776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "b_n, b_ch, b_model = best_top_num(mallet_path, 5, 30, 5)\n",
    "print(b_n, b_ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим список со словами и их весами для каждой темы, а потом определим главную тему у каждого текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(mdl):\n",
    "    tops = mdl.show_topics(-1)\n",
    "    tp_wrds = []\n",
    "    for i in tops:\n",
    "        words = re.findall('\"(.+?)\"', i[1])\n",
    "        wgts = re.findall('(0.[\\d]+?)\\*', i[1])\n",
    "        tp_wrds.append(list(zip(words, wgts)))\n",
    "    return tp_wrds\n",
    "\n",
    "def main_topic(texts, tp_wrds):\n",
    "    m_ts = []\n",
    "    for i in texts:\n",
    "        tps = [0]*len(tp_wrds)\n",
    "        for j in range(len(tp_wrds)):\n",
    "            for x, y in tp_wrds[j]:\n",
    "                tps[j] += float(y)*i.count(x)\n",
    "        m_t = sorted(tps)[-1]\n",
    "        m_ts.append(tps.index(m_t))\n",
    "        \n",
    "    return m_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = get_top_words(b_model)\n",
    "topics = main_topic(texts, top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь, в котором ключ - номер темы, а значение - список текстов этой темы. Потом найдем топ-5 слов для каждого документа по tf-idf и занесем их в датафрейм. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(texts, topics):\n",
    "    ts = {}\n",
    "    for i in range(len(texts)):\n",
    "        if topics[i] in ts:\n",
    "            ts[topics[i]].append(' '.join(texts[i]))\n",
    "        else:\n",
    "            ts[topics[i]] = [' '.join(texts[i])]\n",
    "        \n",
    "    return ts\n",
    "\n",
    "top_t = get_texts(texts[:5000], topics[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = {'Word': [], 'TF-IDF': [], 'Text': [], 'Topic': []}\n",
    "\n",
    "def get_fill_data(top_t):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    for i in top_t:\n",
    "        vectors = vectorizer.fit_transform(top_t[i])\n",
    "        feature_names = vectorizer.get_feature_names()\n",
    "        dense = vectors.todense()\n",
    "        denselist = dense.tolist()\n",
    "        for j in range(len(denselist)):\n",
    "            top_ws = sorted(zip(feature_names, denselist[j]), key= lambda u: u[1], reverse=True)[:5]\n",
    "            for w in top_ws:\n",
    "                n_data['Topic'].append(i)\n",
    "                n_data['Word'].append(w[0])\n",
    "                n_data['TF-IDF'].append(w[1])\n",
    "                n_data['Text'].append(top_t[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fill_data(top_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>TF-IDF</th>\n",
       "      <th>Text</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>car</td>\n",
       "      <td>0.529976</td>\n",
       "      <td>where thing car nntp_poste host park line wond...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>door</td>\n",
       "      <td>0.283337</td>\n",
       "      <td>where thing car nntp_poste host park line wond...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>bricklin</td>\n",
       "      <td>0.194586</td>\n",
       "      <td>where thing car nntp_poste host park line wond...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>lerxst</td>\n",
       "      <td>0.194586</td>\n",
       "      <td>where thing car nntp_poste host park line wond...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>neighborhood</td>\n",
       "      <td>0.194586</td>\n",
       "      <td>where thing car nntp_poste host park line wond...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>poll</td>\n",
       "      <td>0.407783</td>\n",
       "      <td>poll final call summary final call clock repor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>clock</td>\n",
       "      <td>0.364615</td>\n",
       "      <td>poll final call summary final call clock repor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>upgrade</td>\n",
       "      <td>0.236677</td>\n",
       "      <td>poll final call summary final call clock repor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>final</td>\n",
       "      <td>0.207898</td>\n",
       "      <td>poll final call summary final call clock repor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>speed</td>\n",
       "      <td>0.193089</td>\n",
       "      <td>poll final call summary final call clock repor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word    TF-IDF                                               Text  \\\n",
       "0           car  0.529976  where thing car nntp_poste host park line wond...   \n",
       "1          door  0.283337  where thing car nntp_poste host park line wond...   \n",
       "2      bricklin  0.194586  where thing car nntp_poste host park line wond...   \n",
       "3        lerxst  0.194586  where thing car nntp_poste host park line wond...   \n",
       "4  neighborhood  0.194586  where thing car nntp_poste host park line wond...   \n",
       "5          poll  0.407783  poll final call summary final call clock repor...   \n",
       "6         clock  0.364615  poll final call summary final call clock repor...   \n",
       "7       upgrade  0.236677  poll final call summary final call clock repor...   \n",
       "8         final  0.207898  poll final call summary final call clock repor...   \n",
       "9         speed  0.193089  poll final call summary final call clock repor...   \n",
       "\n",
       "   Topic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "5      0  \n",
       "6      0  \n",
       "7      0  \n",
       "8      0  \n",
       "9      0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_df = pd.DataFrame(n_data)\n",
    "n_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coherence score - вычисляет, как часто слова из одного топика встречаются вместе рядом (попарно) и насколько это неслучайно (насколько сильно изменяется вероятность того, что встретится слово 1 при условии, что встретилось слово 2, и так для всех пар слов из топиков. Потом, насколько я поняла, это все усредняется)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
